{"cells":[{"cell_type":"markdown","metadata":{"id":"reE9mtcJgoHy"},"source":["# Introduction to CNN\n","\n","The problem is about **classifying grayscale images of handwritten digits** (28 pixels by 28 pixels), into their 10 categories (0 to 9), exactly like the one in chapter 2. This time will try to solve the problem through a convolutional neural network (CNN) and see if performance improves."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"LF43wDIIgoH5","executionInfo":{"status":"ok","timestamp":1707121914482,"user_tz":-330,"elapsed":5121,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from tensorflow.keras import models, layers, optimizers, losses, metrics\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"markdown","metadata":{"id":"V5BQEoDvgoIC"},"source":["## Build the network\n","\n","A basic convnet will be used: a stack of `Conv2D` and `MaxPooling2D` layers.\n","Importantly, a CNN takes as input tensors of shape (`image_height, image_width, image_channels`), not including the batch dimensions. In this case, we have to configure the CNN to process images of a size compatible with the MNIST database, so it will be of size (28, 28, 1). This will be the input shape to pass to the first layer."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1707121914482,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"},"user_tz":-330},"id":"u4ro-1KRgoID","outputId":"e3008a20-a414-45a7-fc46-dd04d97a0852"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n","                                                                 \n","=================================================================\n","Total params: 55744 (217.75 KB)\n","Trainable params: 55744 (217.75 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # total of 32 Filters\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))      # total of 64 Filters\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))        # total of 64 Filters\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"Sv2qSu5ogoIF"},"source":["The output of every `Conv2D` and `MaxPooling2D` layer is also a tensor of shape (`height, width, channels`). Interesting to note how the dimensions tend to shrink as going deeper in the network. The channel is controlled by the first parameter in `Conv2D` layers.\n","\n","While the the 3rd parameter of the input shape indicates the color channels, in the output of a layer it indicates the number of filters (features) over its input. So, every dimension in the depth axis is a feature (filter), and the 2D tensor is a 2D spatial map of the response of this filter over the input."]},{"cell_type":"markdown","metadata":{"id":"4OBkE5yGgoIH"},"source":["#### Insert a classifier on top of the CNN\n","\n","This is a classification problem, so we need to put the last output tensor of the CNN as input to a densely connected network, similar to the one in chapter 2. We have a class of 10 categories, so the solution will be a 10-way classification, using a final layer of 10 outputs and a `softmax` activation."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1707121914483,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"},"user_tz":-330},"id":"rdfuHugqgoIJ","outputId":"a10ce6cb-7d3b-429d-efc5-47a2b8d3c8b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n","                                                                 \n"," flatten (Flatten)           (None, 576)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                36928     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 93322 (364.54 KB)\n","Trainable params: 93322 (364.54 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))                        # 64 Neurons\n","model.add(layers.Dense(10, activation='softmax'))                     # 10 Neuron\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"VqFgtgh3goIJ"},"source":["Note that the `Flatten` layer produces a vector of shape (`3 * 3 * 64`), which is the output of the last `Conv2D` layer. Operation needed before going through the 2 dense layers"]},{"cell_type":"markdown","metadata":{"id":"ttgHxaJBgoIK"},"source":["## Load dataset and preprocess data\n","\n","`train_images` and `train_labels` form the \"training set\", the data that the model will learn from. The model will then be tested on the \"test set\", `test_images` and `test_labels`. The images are encoded as Numpy arrays, and the labels are simply an array of digits, ranging from 0 to 9. There is a one-to-one correspondence between the images and the labels.\n","\n","Before training, we will preprocess our data by reshaping it into the shape that the CNN expects. We do also need to categorically encode the labels (one-hot)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1017,"status":"ok","timestamp":1707121915474,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"},"user_tz":-330},"id":"uC59cWergoIL","outputId":"98641538-4d97-43f6-ae3f-80ad8b061025"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}],"source":["(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"L36EVY_ngoIM","executionInfo":{"status":"ok","timestamp":1707121915474,"user_tz":-330,"elapsed":10,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"}}},"outputs":[],"source":["train_images = train_images.reshape((60000, 28, 28, 1))\n","train_images = train_images.astype('float32') / 255"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"pcOcvwKdgoIQ","executionInfo":{"status":"ok","timestamp":1707121915475,"user_tz":-330,"elapsed":10,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"}}},"outputs":[],"source":["test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images = test_images.astype('float32') / 255"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"g7JBkIR5goIS","executionInfo":{"status":"ok","timestamp":1707121915475,"user_tz":-330,"elapsed":9,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"}}},"outputs":[],"source":["train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"]},{"cell_type":"markdown","metadata":{"id":"ZFSl-HVqgoIT"},"source":["## Compile and train model"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMu1wnBmgoIT","outputId":"a398a303-01d9-4c13-940d-786d62a53b18","executionInfo":{"status":"ok","timestamp":1707122178720,"user_tz":-330,"elapsed":263254,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","938/938 [==============================] - 53s 55ms/step - loss: 0.1817 - accuracy: 0.9429\n","Epoch 2/5\n","938/938 [==============================] - 47s 50ms/step - loss: 0.0461 - accuracy: 0.9856\n","Epoch 3/5\n","938/938 [==============================] - 46s 49ms/step - loss: 0.0320 - accuracy: 0.9904\n","Epoch 4/5\n","938/938 [==============================] - 48s 51ms/step - loss: 0.0256 - accuracy: 0.9921\n","Epoch 5/5\n","938/938 [==============================] - 47s 50ms/step - loss: 0.0194 - accuracy: 0.9938\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7c64d9a7a410>"]},"metadata":{},"execution_count":8}],"source":["model.compile(\n","    optimizer='rmsprop',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","model.fit(train_images, train_labels, epochs=5, batch_size=64)"]},{"cell_type":"markdown","metadata":{"id":"oS-uB8y8goIU"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2484,"status":"ok","timestamp":1707122181196,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"},"user_tz":-330},"id":"AIhHuNZugoIU","outputId":"40db458a-c9bd-4da3-c9dd-916a4a83410c"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 3s 8ms/step - loss: 0.0284 - accuracy: 0.9919\n"]}],"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"stvjv1EwgoIU","outputId":"c955e61d-cda1-491e-c4e2-379edd85a397","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707122181197,"user_tz":-330,"elapsed":8,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["test_acc: 0.9919000267982483\n"]}],"source":["print('test_acc:', test_acc)"]},{"cell_type":"markdown","metadata":{"id":"ky9VeBQCgoIV"},"source":["The test set accuracy turns out to be *99.1%*, which is quite an improvement from the fully connected network in chapter 2, which reached *97.8%* accuracy."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"QFkA9Wl7goIV","executionInfo":{"status":"ok","timestamp":1707122181197,"user_tz":-330,"elapsed":6,"user":{"displayName":"kumod kumar gupta","userId":"07478795497397479293"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}